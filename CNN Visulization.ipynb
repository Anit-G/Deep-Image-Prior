{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.learnopencv.com/pytorch-for-beginners-image-classification-using-pre-trained-models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "import random\n",
    "\n",
    "def hide_toggle(for_next=False):\n",
    "    this_cell = \"\"\"$('div.cell.code_cell.rendered.selected')\"\"\"\n",
    "    next_cell = this_cell + '.next()'\n",
    "\n",
    "    toggle_text = 'Toggle show/hide'  # text shown on toggle link\n",
    "    target_cell = this_cell  # target cell to control with toggle\n",
    "    js_hide_current = ''  # bit of JS to permanently hide code in current cell (only when toggling next cell)\n",
    "\n",
    "    if for_next:\n",
    "        target_cell = next_cell\n",
    "        toggle_text += ' next cell'\n",
    "        js_hide_current = this_cell + '.find(\"div.input\").hide();'\n",
    "\n",
    "    js_f_name = 'code_toggle_{}'.format(str(random.randint(1,2**64)))\n",
    "\n",
    "    html = \"\"\"\n",
    "        <script>\n",
    "            function {f_name}() {{\n",
    "                {cell_selector}.find('div.input').toggle();\n",
    "            }}\n",
    "\n",
    "            {js_hide_current}\n",
    "        </script>\n",
    "\n",
    "        <a href=\"javascript:{f_name}()\">{toggle_text}</a>\n",
    "    \"\"\".format(\n",
    "        f_name=js_f_name,\n",
    "        cell_selector=target_cell,\n",
    "        js_hide_current=js_hide_current, \n",
    "        toggle_text=toggle_text\n",
    "    )\n",
    "\n",
    "    return HTML(html)\n",
    "\n",
    "hide_toggle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchvision import models\n",
    "import torch\n",
    "import torch\n",
    "import torchvision #provides CV functionality and Datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "device = 'cuda'#changes CPU to run on GPU\n",
    "\n",
    "hide_toggle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TIME TO PRINT THE WEIGHTS OF A CNN IN IMAGE FORM\n",
    "\n",
    "for p in resnet101.parameters():\n",
    "    print(p)\n",
    "    \n",
    "for name, param in resnet101.state_dict().items():\n",
    "    print(name)\n",
    "    print(param)\n",
    "    \n",
    "\n",
    "for name, param in resnet101.state_dict().items():\n",
    "    if 'conv' in name:\n",
    "        print(name)\n",
    "        \n",
    "\n",
    "for name, layer in resnet101.state_dict().items():\n",
    "    print(layer)\n",
    "\n",
    "hide_toggle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "resnet101 = models.resnet101(pretrained=True)\n",
    "\n",
    "from torchvision import transforms\n",
    "transform = transforms.Compose([            #[1]\n",
    "    transforms.Resize(256),                    #[2]\n",
    "    transforms.CenterCrop(224),                #[3]\n",
    "    transforms.ToTensor(),                     #[4]\n",
    "    transforms.Normalize(                      #[5]\n",
    "    mean=[0.485, 0.456, 0.406],                #[6]\n",
    "    std=[0.229, 0.224, 0.225]                  #[7]\n",
    " )])\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "img = Image.open(\"dog.jpg\")\n",
    "img_t=transform(img)\n",
    "batch_t=torch.unsqueeze(img_t,0)\n",
    "\n",
    "hide_toggle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet101\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visulization using activation maximization\n",
    "https://towardsdatascience.com/how-to-visualize-convolutional-features-in-40-lines-of-code-70b7d87b0030 \n",
    "visulizing using hooks\n",
    "https://blog.paperspace.com/pytorch-hooks-gradient-clipping-debugging/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Try:-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just managed to extract features from the end of each bottlneck layer in the resnet101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dog input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hide_toggle(for_next=True) #The hook for the resnet101 for the dog.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first the sequntial layer is printed in its entirety then the bottleneck layers inside that sequential layer are printed\n",
    "#thus the entire resnet101 is printed twice\n",
    "\n",
    "net = resnet101\n",
    "visualisation = {}\n",
    "\n",
    "def hook_fn(m, i, o):\n",
    "    visualisation[m] = o.clone().detach()\n",
    "\n",
    "def get_all_layers(net):\n",
    "    for name, layer in net._modules.items():\n",
    "        print(layer)\n",
    "        #If it is a sequential, don't register a hook on it\n",
    "        # but recursively register hook on all it's module children\n",
    "        if isinstance(layer, nn.Sequential):\n",
    "            get_all_layers(layer)\n",
    "        else:\n",
    "            # it's a non sequential. Register a hook\n",
    "            layer.register_forward_hook(hook_fn)\n",
    "\n",
    "\n",
    "get_all_layers(net)\n",
    "\n",
    "  \n",
    "resnet101.eval()\n",
    "out = resnet101(batch_t)\n",
    "print(out.shape)\n",
    "\n",
    "#printing the results of the input dog.jpg\n",
    "'''with open('imagenet_classes.txt') as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "    \n",
    "_, index = torch.max(out, 1)\n",
    "\n",
    "percentage = torch.nn.functional.softmax(out, dim=1)[0] * 100\n",
    "\n",
    "print(classes[index[0]],percentage[index[0]].item())'''\n",
    "\n",
    "\n",
    "# Just to check whether we got all layers\n",
    "#visualisation.keys()    #output includes sequential layers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing all the layer information\n",
    "#U will notice i didn't access any of the convo layers inside the bottlenecks\n",
    "num = 1\n",
    "for layer in visualisation.keys():\n",
    "    print(str(num)+\" \"+str(layer)+\" \")\n",
    "    num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualisation.values()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Saving all the features as images in the project file\n",
    "num=0\n",
    "for i in visualisation.values(): \n",
    "    print(i.size())\n",
    "    num+=1\n",
    "    for filters in range(20):\n",
    "        if i.size(2)!=1:\n",
    "            img = np.asarray(i[0,filters].view(i.size(2),i.size(2)))\n",
    "            plt.imsave(\"layer_\"+str(num)+\"_filter_\"+str(filters)+\"_Tensor_size_\"+str(i.size())+\".jpg\", img)\n",
    "            im = Image.open(\"layer_\"+str(num)+\"_filter_\"+str(filters)+\"_Tensor_size_\"+str(i.size())+\".jpg\")\n",
    "            im_resized = im.resize(size)\n",
    "            im_resized.save(\"layer_\"+str(num)+\"_filter_\"+str(filters)+\"_Tensor_size_\"+str(i.size())+\".jpg\", \"PNG\")\n",
    "        else: \n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating a random image(random numpy array 3 color channels)\n",
    "'''sz = 256\n",
    "img = np.uint8(np.random.uniform(150, 180, (256, 256, 3)))/25\n",
    "'''\n",
    "\n",
    "#creating a pytorch variable\n",
    "#first transform the img into a tensor then define Variable\n",
    "img_t = 150*torch.randn(1,3,256,256)    #tensor\n",
    "img = np.uint8(img_t.reshape(256,256,3))\n",
    "plt.imshow(img)\n",
    "#print(img_t)\n",
    "img_var = Variable(img_t, requires_grad=True)#wrap the tensor in pytorch variable\n",
    "\n",
    "hide_toggle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_all_layers(net)\n",
    "out = resnet101(img_var)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualisation.values()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Saving all the features as images in the project file\n",
    "num=0\n",
    "size = 256,256\n",
    "for i in visualisation.values(): \n",
    "    print(i.size())\n",
    "    num+=1\n",
    "    for filters in range(20):\n",
    "        if i.size(2)!=1:\n",
    "            img = np.asarray(i[0,filters].view(i.size(2),i.size(2)))\n",
    "            plt.imsave(\"layer_\"+str(num)+\"_filter_\"+str(filters)+\"_Tensor_size_\"+str(i.size())+\".jpg\", img)\n",
    "            im = Image.open(\"layer_\"+str(num)+\"_filter_\"+str(filters)+\"_Tensor_size_\"+str(i.size())+\".jpg\")\n",
    "            im_resized = im.resize(size)\n",
    "            im_resized.save(\"layer_\"+str(num)+\"_filter_\"+str(filters)+\"_Tensor_size_\"+str(i.size())+\".jpg\", \"PNG\")\n",
    "        else: \n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second try:-\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there are a total of 104 convolutional layers in the resnet101 structure 4 of which are part of sequential layers inside \n",
    "#the bottleneck layers and are there for downsampleing the image. The following layers will be used for extracting features\n",
    "num=1\n",
    "for name, layer in net.named_modules():\n",
    "    if 'conv' in name:\n",
    "        print(str(num)+\" \"+str(name))\n",
    "        print(layer)\n",
    "        num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,layer in net.named_modules():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this namelist will be used to name the images later on\n",
    "n=0\n",
    "namelist=[]\n",
    "for name, layer in net.named_modules():\n",
    "    if 'Bottleneck' not in str(layer):\n",
    "        print(name)\n",
    "        namelist.append(name)\n",
    "        print(n)\n",
    "        n+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RANDOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Registering hooks in each of the layers of the resnet\n",
    "'''the way it registers is a bit weird \n",
    "First is hooks every individual layer inside a bottleneck then the bottleneck itself\n",
    "after that it hooks the sequential layer as a whole after hooking all the bottleneck layers\n",
    "finally the entire resnet is hooked'''\n",
    "\n",
    "visualisation = {}\n",
    "\n",
    "def hook_fn(m, i, o):\n",
    "    visualisation[m] = o.clone().detach()\n",
    "\n",
    "def get_features(net):\n",
    "    for name, layer in net.named_modules():\n",
    "        layer.register_forward_hook(hook_fn)\n",
    "\n",
    "        \n",
    "get_features(resnet101)\n",
    "out = resnet101(img_var)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in visualisation.keys():\n",
    "    if 'Bottleneck'not in str(i):\n",
    "        print('_________________')\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in visualisation.values():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos=0\n",
    "for name in visualisation.keys():\n",
    "    if 'Bottleneck' not in str(name):\n",
    "        num=0\n",
    "        for values in visualisation.values():\n",
    "            if num==pos:\n",
    "                print(str(name))\n",
    "                print(namelist[pos])\n",
    "                print(pos)\n",
    "                pos+=1\n",
    "                break\n",
    "            num+=1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pos=0\n",
    "size = 256,256\n",
    "for name in visualisation.keys():\n",
    "    if 'Bottleneck' not in str(name):\n",
    "        num=0\n",
    "        for values in visualisation.values():\n",
    "            if num==pos:\n",
    "                print(values.size())\n",
    "                print(pos)\n",
    "                for filters in range(10):\n",
    "                    if values.size(2)!=1:\n",
    "                        img = np.asarray(values[0,filters].view(values.size(2),values.size(2)))\n",
    "                        plt.imsave(str(pos)+'_'+str(namelist[pos])+\"_filter_\"+str(filters)+\"_Tensor_size_\"+str(values.size())+\".jpg\", img)\n",
    "                        im = Image.open(str(pos)+'_'+str(namelist[pos])+\"_filter_\"+str(filters)+\"_Tensor_size_\"+str(values.size())+\".jpg\")\n",
    "                        im_resized = im.resize(size)\n",
    "                        im_resized.save(str(pos)+'_'+str(namelist[pos])+\"_filter_\"+str(filters)+\"_Tensor_size_\"+str(values.size())+\".jpg\", \"PNG\")\n",
    "                    else: \n",
    "                        break\n",
    "                pos+=1\n",
    "                break\n",
    "            num+=1\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet101.eval()\n",
    "out = resnet101(batch_t)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos=0\n",
    "size = 256,256\n",
    "for name in visualisation.keys():\n",
    "    if 'Bottleneck' not in str(name):\n",
    "        num=0\n",
    "        for values in visualisation.values():\n",
    "            if num==pos:\n",
    "                print(values.size())\n",
    "                print(pos)\n",
    "                for filters in range(10):\n",
    "                    if values.size(2)!=1:\n",
    "                        img = np.asarray(values[0,filters].view(values.size(2),values.size(2)))\n",
    "                        plt.imsave(str(pos)+'_'+str(namelist[pos])+\"_filter_\"+str(filters)+\"_Tensor_size_\"+str(values.size())+\".jpg\", img)\n",
    "                        im = Image.open(str(pos)+'_'+str(namelist[pos])+\"_filter_\"+str(filters)+\"_Tensor_size_\"+str(values.size())+\".jpg\")\n",
    "                        im_resized = im.resize(size)\n",
    "                        im_resized.save(str(pos)+'_'+str(namelist[pos])+\"_filter_\"+str(filters)+\"_Tensor_size_\"+str(values.size())+\".jpg\", \"PNG\")\n",
    "                    else: \n",
    "                        break\n",
    "                pos+=1\n",
    "                break\n",
    "            num+=1\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
